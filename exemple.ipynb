{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, make_scorer,r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/x_train.csv')  \n",
    "y_data = pd.read_csv('data/y_train.csv')\n",
    "test_data = pd.read_csv('data/x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_weighted_rmse(y_true, y_pred):\n",
    "    weights = np.where(y_true < 0.5, 1, 1.2)\n",
    "    error_per_class = weights * (y_true - y_pred) ** 2\n",
    "    mean_error = np.mean(error_per_class)\n",
    "    return np.sqrt(mean_error)\n",
    "\n",
    "custom_scorer = make_scorer(custom_weighted_rmse, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression de la colonne 'ID' (pas utile pour l'entraînement)\n",
    "X = train_data.drop(columns=['ID'])\n",
    "y = y_data.drop(columns=['ID'])\n",
    "\n",
    "# Diviser les données en ensemble d'entraînement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application d un standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (162346, 13)\n",
      "X_train_poly.shape: (162346, 105)\n"
     ]
    }
   ],
   "source": [
    "#Now, we extract polynomial features and interactions up to a degree of 2\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.fit(X_train_scaled)\n",
    "X_train_poly = poly.transform(X_train_scaled)\n",
    "X_val_poly = poly.transform(X_val_scaled)\n",
    "print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "print(\"X_train_poly.shape: {}\".format(X_train_poly.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude classique 1 seul Model pour prédire "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection des Modeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche à tester sur un grand nombre de datasets afin de voir si un modele marche mieux ou nom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBRegressor\n",
      "Model: LinearRegression\n",
      "Model: Ridge\n",
      "Model: Lasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapdu\\COMMUN\\Dauphine\\Identification-Gaz-Toxiques-BERTIN\\env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ElasticNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapdu\\COMMUN\\Dauphine\\Identification-Gaz-Toxiques-BERTIN\\env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeRegressor\n",
      "Model: RandomForestRegressor\n",
      "Model: KNeighborsRegressor\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'XGBoost' : XGBRegressor(),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "    'Random Forest Regression': RandomForestRegressor(),\n",
    "    'K-Neighbors Regression': KNeighborsRegressor()}\n",
    "\n",
    "res = list()\n",
    "for mod in models.values() :\n",
    "    print(f\"Model: {mod.__class__.__name__}\")\n",
    "    # Initialiser le modèle\n",
    "    model = mod\n",
    "    # Entraîner le modèle de base\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    # Évaluation du modèle\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred) \n",
    "    custom_rmse = custom_weighted_rmse(y_val, y_pred)\n",
    "    # Validation croisée\n",
    "    #cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring=custom_scorer)\n",
    "    res.append([mod.__class__.__name__,custom_rmse, mse,r2,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>custom_rmse</th>\n",
       "      <th>mse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.217702</td>\n",
       "      <td>0.041588</td>\n",
       "      <td>0.043445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.217702</td>\n",
       "      <td>0.041588</td>\n",
       "      <td>0.043445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.178308</td>\n",
       "      <td>0.028143</td>\n",
       "      <td>0.272862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.178304</td>\n",
       "      <td>0.028143</td>\n",
       "      <td>0.272863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.026284</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.973690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.022887</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.947358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.014776</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.993547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.997001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  custom_rmse       mse        r2\n",
       "3                  Lasso     0.217702  0.041588  0.043445\n",
       "4             ElasticNet     0.217702  0.041588  0.043445\n",
       "2                  Ridge     0.178308  0.028143  0.272862\n",
       "1       LinearRegression     0.178304  0.028143  0.272863\n",
       "7    KNeighborsRegressor     0.026284  0.000649  0.973690\n",
       "0           XGBRegressor     0.022887  0.000487  0.947358\n",
       "5  DecisionTreeRegressor     0.014776  0.000204  0.993547\n",
       "6  RandomForestRegressor     0.009530  0.000086  0.997001"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(res,columns=[\"model\",\"custom_rmse\",\"mse\",\"r2\"]).sort_values(by=\"custom_rmse\",ascending=False)\n",
    "# res[\"cv_mean\"] = res['cv_score'].apply(lambda x : np.mean(x))\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le meilleur model semble etre le random Forest Regressor. On va donc essayer d optimiser les parametres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation des hyperparamètres - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va commencer par utiliser un modèle de Random Forest simple que l'on va evaluer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur quadratique moyenne pondérée (RMSE) sur les données de validation : 0.11800015451516697\n"
     ]
    }
   ],
   "source": [
    "# model_rf = RandomForestRegressor(n_estimators=5, max_depth=7, min_samples_split=0.01, min_samples_leaf=30, random_state=42)\n",
    "model_rf = RandomForestRegressor(n_estimators=5, max_depth=7, min_samples_split=0.01, min_samples_leaf=30, random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred = model_rf.predict(X_val)\n",
    "rmse = custom_weighted_rmse(y_val, y_pred)\n",
    "print(f\"Erreur quadratique moyenne pondérée (RMSE) sur les données de validation : {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debut de l'optimisation des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "# Optimisation des hyperparamètres avec GridSearchCV\n",
    "# param_grid = {\n",
    "#     'n_estimators': [5, 10, 20],\n",
    "#     'max_depth': [7, 10, 15],\n",
    "#     'min_samples_split': [0.01, 0.05, 0.1],\n",
    "#     'min_samples_leaf': [30, 50, 70]\n",
    "# }\n",
    "param_grid = {\n",
    "    'n_estimators': [11,12,13],\n",
    "    'max_depth': [15,20],\n",
    "    'min_samples_split': [0.01],\n",
    "    'min_samples_leaf': [30]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model_rf, param_grid=param_grid, cv=5, scoring=custom_scorer, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train_poly, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "# Meilleurs hyperparamètres\n",
    "print(f\"Meilleurs hyperparamè tres : {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation finale sur les données de validation\n",
    "y_pred = best_model.predict(X_val_poly)\n",
    "best_mse = mean_squared_error(y_val, y_pred)\n",
    "best_r2 = r2_score(y_val, y_pred)\n",
    "custom_mse = custom_weighted_rmse(y_val, y_pred)\n",
    "print(f\"Best Mean Squared Error: {best_mse}\")\n",
    "print(f\"Best R^2 Score: {best_r2}\")\n",
    "print(f\"Custom MSE sur les données de validation : {custom_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Squared Error: 0.007539696090108572\n",
      "Best R^2 Score: 0.7263825866396201\n",
      "Custom MSE sur les données de validation : 0.09115404934287714\n"
     ]
    }
   ],
   "source": [
    "# Évaluation finale sur les données de validation\n",
    "y_pred = best_model.predict(X_val_poly)\n",
    "best_mse = mean_squared_error(y_val, y_pred)\n",
    "best_r2 = r2_score(y_val, y_pred)\n",
    "custom_mse = custom_weighted_rmse(y_val, y_pred)\n",
    "print(f\"Best Mean Squared Error: {best_mse}\")\n",
    "print(f\"Best R^2 Score: {best_r2}\")\n",
    "print(f\"Custom MSE sur les données de validation : {custom_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross-Validation Scores: [0.08968177 0.09232792 0.09127526 0.09227364 0.09024462]\n",
      "Mean Best Cross-Validation Score : 0.09116064294290777\n"
     ]
    }
   ],
   "source": [
    "# Effectuer une validation croisée à 5 folds\n",
    "best_cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring=custom_scorer)\n",
    "print(f\"Best Cross-Validation Scores: {-best_cv_scores}\")\n",
    "print(f\"Mean Best Cross-Validation Score : {-best_cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application des modeles avec Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBRegressor\n",
      "Model: LinearRegression\n",
      "Model: Ridge\n",
      "Model: Lasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapdu\\COMMUN\\Dauphine\\Identification-Gaz-Toxiques-BERTIN\\env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ElasticNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapdu\\COMMUN\\Dauphine\\Identification-Gaz-Toxiques-BERTIN\\env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeRegressor\n",
      "Model: RandomForestRegressor\n",
      "Model: KNeighborsRegressor\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'XGBoost' : XGBRegressor(),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "    'Random Forest Regression': RandomForestRegressor(n_estimators=5, max_depth=7, min_samples_split=0.01, min_samples_leaf=30, random_state=42),\n",
    "    'K-Neighbors Regression': KNeighborsRegressor()}\n",
    "\n",
    "res = list()\n",
    "for mod in models.values() :\n",
    "    print(f\"Model: {mod.__class__.__name__}\")\n",
    "    # Initialiser le modèle\n",
    "    model = mod\n",
    "    # Entraîner le modèle de base\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    # Évaluation du modèle\n",
    "    y_pred = model.predict(X_val_poly)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred) \n",
    "    custom_rmse = custom_weighted_rmse(y_val, y_pred)\n",
    "    # Validation croisée\n",
    "    #cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring=custom_scorer)\n",
    "    res.append([mod.__class__.__name__,\"Polynomial Features\",custom_rmse, mse,r2,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Type</th>\n",
       "      <th>custom_rmse</th>\n",
       "      <th>mse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>Polynomial Features</td>\n",
       "      <td>0.217702</td>\n",
       "      <td>0.041588</td>\n",
       "      <td>0.043445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>Polynomial Features</td>\n",
       "      <td>0.217137</td>\n",
       "      <td>0.041380</td>\n",
       "      <td>0.051383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>Polynomial Features</td>\n",
       "      <td>0.149709</td>\n",
       "      <td>0.020049</td>\n",
       "      <td>0.481192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Polynomial Features</td>\n",
       "      <td>0.149502</td>\n",
       "      <td>0.019998</td>\n",
       "      <td>0.482415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>Polynomial Features</td>\n",
       "      <td>0.117838</td>\n",
       "      <td>0.012479</td>\n",
       "      <td>0.611522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>Polynomial Features</td>\n",
       "      <td>0.020608</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.948205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>Polynomial Features</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.986720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>Polynomial Features</td>\n",
       "      <td>0.017629</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.989868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model                 Type  custom_rmse       mse        r2\n",
       "3                  Lasso  Polynomial Features     0.217702  0.041588  0.043445\n",
       "4             ElasticNet  Polynomial Features     0.217137  0.041380  0.051383\n",
       "2                  Ridge  Polynomial Features     0.149709  0.020049  0.481192\n",
       "1       LinearRegression  Polynomial Features     0.149502  0.019998  0.482415\n",
       "6  RandomForestRegressor  Polynomial Features     0.117838  0.012479  0.611522\n",
       "0           XGBRegressor  Polynomial Features     0.020608  0.000395  0.948205\n",
       "7    KNeighborsRegressor  Polynomial Features     0.019814  0.000368  0.986720\n",
       "5  DecisionTreeRegressor  Polynomial Features     0.017629  0.000286  0.989868"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pd.DataFrame(res,columns=[\"model\",\"Type\",\"custom_rmse\",\"mse\",\"r2\"]).sort_values(by=\"custom_rmse\",ascending=False)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction de 1 model par Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection de modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVR\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Liste des modèles\n",
    "models = {\n",
    "    # 'XGBoost' : XGBRegressor(),\n",
    "    # 'Linear Regression': LinearRegression(),\n",
    "    # 'Ridge Regression': Ridge(),\n",
    "    # 'Lasso Regression': Lasso(),\n",
    "    # 'ElasticNet': ElasticNet(),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    #'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "    #'Random Forest Regression': RandomForestRegressor(),\n",
    "    'Gradient Boosting Regression': GradientBoostingRegressor(),\n",
    "    #'K-Neighbors Regression': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "res = list()\n",
    "\n",
    "for mod in models.values():\n",
    "    print(f\"Model: {mod.__class__.__name__}\")\n",
    "    \n",
    "    # Initialiser le modèle MultiOutputRegressor avec le modèle de base\n",
    "    multi_target_model = MultiOutputRegressor(mod)\n",
    "    \n",
    "    # Entraîner le modèle multi-cible\n",
    "    multi_target_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédictions pour toutes les cibles\n",
    "    y_pred = multi_target_model.predict(X_val)\n",
    "      \n",
    "    # Calcul des métriques pour chaque colonne cible\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    custom_rmse = custom_weighted_rmse(y_val, y_pred)  # Remarque: tu peux ajuster cette fonction selon tes besoins\n",
    "    \n",
    "    # Ajouter les résultats dans la liste\n",
    "    res.append([mod.__class__.__name__, custom_rmse, mse, r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(res,columns=[\"model\",\"custom_rmse\",\"mse\",\"r2\"]).sort_values(by=\"custom_rmse\",ascending=False)\n",
    "# res[\"cv_mean\"] = res['cv_score'].apply(lambda x : np.mean(x))\n",
    "res.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Prédictions finales (sur test_data, si disponible)\n",
    "test_pred = best_model.predict(test_data.drop(columns=['ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement des résultats\n",
    "\n",
    "output = pd.DataFrame(test_pred, columns=[f'c{i}' for i in range(1, 24)])\n",
    "# Ajouter la colonne \"ID\" au début\n",
    "output.insert(0, 'ID', test_data['ID'])\n",
    "output.to_csv('predictions/best_prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
